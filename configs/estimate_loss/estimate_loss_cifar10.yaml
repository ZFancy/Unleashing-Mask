# Architecture
arch: DenseNet

# ===== Dataset ===== #
data: <path/to/data-dir>
set: CIFAR10
name: estimate_loss_cifar10

# ===== Learning Rate Policy ======== #
optimizer: sgd
lr: 0.1
lr_policy: cosine_lr

# ===== Network training config ===== #
pretrained: runs/pretrained_models/densenet_cifar10_last.state
multigpu: [0]
epochs: 100
weight_decay: 0.0001
droprate: 0.3
momentum: 0.9
batch_size: 512
num_classes: 10
criterion: CrossEntropyLoss

# ===== Sparsity =========== #
conv_type: SubnetConv
linear_type: SubnetLinear
bn_type: NonAffineBatchNorm
init: kaiming_normal
mode: fan_in
nonlinearity: relu
prune_rate: 0.965
freeze_weights: True

# ===== Hardware setup ===== #
workers: 4
